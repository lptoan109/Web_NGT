{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12870874,"sourceType":"datasetVersion","datasetId":8141736}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CÀI ĐẶT & CẤU HÌNH (SETUP & CONFIGURATION)\n\n# 0.1. Cài đặt các thư viện cần thiết\n!pip install -q fpdf2 noisereduce librosa tensorflow scikit-learn matplotlib seaborn pytz PyDrive2\n\n# 0.2. Import thư viện\nimport os\nimport glob\nimport random\nimport datetime\nimport pytz\nimport shutil\nimport joblib\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom fpdf import FPDF\nfrom tqdm.notebook import tqdm\nimport librosa\nimport noisereduce as nr\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom kaggle_secrets import UserSecretsClient\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom tensorflow.keras.regularizers import l2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T14:19:33.514847Z","iopub.execute_input":"2025-08-26T14:19:33.515082Z","iopub.status.idle":"2025-08-26T14:19:57.717082Z","shell.execute_reply.started":"2025-08-26T14:19:33.515057Z","shell.execute_reply":"2025-08-26T14:19:57.716312Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"2025-08-26 14:19:47.062722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756217987.242812      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756217987.294228      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# THIẾT LẬP CẤU HÌNH\n# 0.4. Thiết lập SEED để đảm bảo kết quả tái lặp\nSEED = 42\ndef set_seed(seed_value):\n    \"\"\"Cố định seed cho các thư viện để đảm bảo kết quả nhất quán.\"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\nset_seed(SEED)\n\n# 0.5. Thiết lập phông chữ (đã được đơn giản hóa)\nfont_path = None # Sẽ sử dụng font mặc định\n\n# 0.6. Cấu hình các đường dẫn và tham số\n# --- CẤU HÌNH KAGGLE DATASET (QUAN TRỌNG) ---\nKAGGLE_PROCESSED_DATA_PATH = \"/kaggle/input/ngt-spectrogram-id/\" \n\n# --- CẤU HÌNH KẾT NỐI GOOGLE DRIVE (TÙY CHỌN, ĐỂ LƯU KẾT QUẢ) ---\nDRIVE_RESULTS_FOLDER_ID = '13DW3yr_AVDDbu-Onv58LKLE3TaPuJRDq' \n\n# --- Đường dẫn trên máy ảo Kaggle (Không cần sửa) ---\nKAGGLE_OUTPUT_PATH = \"/kaggle/working/output_results\"\nos.makedirs(KAGGLE_OUTPUT_PATH, exist_ok=True)\n\n# --- Các thông số cấu hình thử nghiệm ---\nCLASSES_TO_TRAIN = ['covid', 'asthma', 'healthy', 'tuberculosis']\nALL_CLASSES = ['healthy', 'asthma', 'covid', 'tuberculosis']\nN_SPLITS = 5\nTEST_SPLIT_RATIO = 0.15\nUSE_DATA_AUGMENTATION = False\nUSE_FOCAL_LOSS = True\nMODEL_ID = f'ResNet50V2_CV_{\"_\".join(CLASSES_TO_TRAIN)}'\nEPOCHS = 50\nBATCH_SIZE = 64\nLEARNING_RATE = 3e-5\nEARLY_STOPPING_PATIENCE = 7\nMIN_DELTA = 1e-4\nSHUFFLE_BUFFER_SIZE = 2048 \n\n# Các tham số không đổi\nSAMPLE_RATE = 16000\nN_MELS = 128\nN_FFT = 2048\nHOP_LENGTH = 512\nSILENCE_THRESHOLD_DB = 20\nIMG_SIZE = (128, 157)\nINPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T14:19:57.718888Z","iopub.execute_input":"2025-08-26T14:19:57.719451Z","iopub.status.idle":"2025-08-26T14:19:57.726715Z","shell.execute_reply.started":"2025-08-26T14:19:57.719427Z","shell.execute_reply":"2025-08-26T14:19:57.725975Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# KHỞI TẠO CÁC HÀM CẦN THIẾT\n\ndef get_patient_id(filepath, class_name):\n    filename = os.path.basename(filepath)\n    if class_name.lower() in ['asthma', 'covid', 'healthy']:\n        return filename.split('_')[0]\n    elif class_name.lower() == 'tuberculosis':\n        return '_'.join(filename.split('_')[:-1]).replace('.npy', '')\n    else:\n        return filename.split('_')[0]\n        \ndef parse_and_process(filepath, label_onehot):\n    \"\"\"Hàm đọc file, stack kênh, chuẩn hóa và làm sạch.\"\"\"\n    def _read_npy(path):\n        return np.load(path.decode()).astype(np.float32)\n    \n    spec = tf.numpy_function(_read_npy, [filepath], tf.float32)\n    spec = tf.stack([spec, spec, spec], axis=-1)\n    spec.set_shape(INPUT_SHAPE)\n    \n    spec_shape = tf.shape(spec)\n    spec_flat = tf.reshape(spec, (1, -1))\n    \n    def _scale(data):\n        scaled_data = scaler.transform(data)\n        # Luôn làm sạch dữ liệu ngay sau khi scale\n        return np.nan_to_num(scaled_data)\n    \n    scaled_flat = tf.numpy_function(_scale, [spec_flat], tf.float32)\n    spec_scaled = tf.reshape(scaled_flat, spec_shape)\n    \n    return spec_scaled, label_onehot\n\ndef augment(spectrogram, label):\n    \"\"\"Hàm áp dụng augmentation.\"\"\"\n    spectrogram = spec_augment(spectrogram)\n    return spectrogram, label\n    \ndef focal_loss_from_logits_optimized(active_indices, gamma=2.0, alpha=0.25):\n    \"\"\"\n    Hàm Focal Loss phiên bản tối ưu, nhận active_indices từ bên ngoài.\n    \"\"\"\n    def focal_loss_fixed(y_true, y_pred):\n        y_true = tf.cast(y_true, 'float32')\n\n        # Không cần tính lại active_indices, chỉ cần sử dụng\n        y_true_filtered = tf.gather(y_true, active_indices, axis=-1)\n        y_pred_filtered = tf.gather(y_pred, active_indices, axis=-1)\n\n        # Phần còn lại giữ nguyên\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n            labels=y_true_filtered, logits=y_pred_filtered\n        )\n        \n        probs = tf.nn.softmax(y_pred_filtered)\n        pt = tf.reduce_sum(y_true_filtered * probs, axis=-1)\n        \n        focal_term = (1.0 - pt) ** gamma\n        loss = alpha * focal_term * cross_entropy\n        return loss\n        \n    return focal_loss_fixed\n\n# HÀM SPEC_AUGMENT ĐÃ SỬA LỖI\ndef spec_augment(spectrogram, time_masking_para=40, frequency_masking_para=15,\n                 num_time_masks=1, num_freq_masks=1):\n    \"\"\"\n    Hàm SpecAugment đã được sửa lỗi để làm việc với shape (freq, time, channels).\n    \"\"\"\n    # Lấy ra các chiều để làm việc\n    freq_bins = tf.shape(spectrogram)[0]\n    time_steps = tf.shape(spectrogram)[1]\n    \n    spectrogram_aug = spectrogram\n\n    # 1. Frequency Masking (che một khoảng tần số)\n    for _ in range(num_freq_masks):\n        f = tf.random.uniform(shape=(), minval=0, maxval=frequency_masking_para, dtype=tf.int32)\n        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n\n        # Tạo một \"mặt nạ\" 1D cho chiều tần số\n        freq_mask_1d = tf.concat([\n            tf.ones(shape=(f0,), dtype=spectrogram.dtype),\n            tf.zeros(shape=(f,), dtype=spectrogram.dtype),\n            tf.ones(shape=(freq_bins - f0 - f,), dtype=spectrogram.dtype)\n        ], axis=0)\n        \n        # Reshape mặt nạ để nó có thể nhân với ảnh phổ 3D\n        # Shape sẽ là (freq, 1, 1) để broadcast qua chiều thời gian và kênh\n        freq_mask_3d = tf.reshape(freq_mask_1d, (freq_bins, 1, 1))\n        spectrogram_aug = spectrogram_aug * freq_mask_3d\n\n    # 2. Time Masking (che một khoảng thời gian)\n    for _ in range(num_time_masks):\n        t = tf.random.uniform(shape=(), minval=0, maxval=time_masking_para, dtype=tf.int32)\n        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n\n        # Tạo một \"mặt nạ\" 1D cho chiều thời gian\n        time_mask_1d = tf.concat([\n            tf.ones(shape=(t0,), dtype=spectrogram.dtype),\n            tf.zeros(shape=(t,), dtype=spectrogram.dtype),\n            tf.ones(shape=(time_steps - t0 - t,), dtype=spectrogram.dtype)\n        ], axis=0)\n\n        # Reshape mặt nạ để nó có thể nhân với ảnh phổ 3D\n        # Shape sẽ là (1, time, 1) để broadcast qua chiều tần số và kênh\n        time_mask_3d = tf.reshape(time_mask_1d, (1, time_steps, 1))\n        spectrogram_aug = spectrogram_aug * time_mask_3d\n        \n    return spectrogram_aug\n\ndef create_model(input_shape, num_classes):\n    \n    # 1. Khởi tạo mô hình\n    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    # 2. Đóng băng các lớp ban đầu (ví dụ: 100 lớp đầu tiên)\n    # ResNet-50V2 có khoảng 190 lớp. Đóng băng một nửa là mức khởi điểm tốt.\n    FREEZE_UNTIL_LAYER = 100\n    for layer in base_model.layers[:FREEZE_UNTIL_LAYER]:\n        layer.trainable = False\n        \n    # 3. Đảm bảo phần còn lại của mô hình được huấn luyện\n    # Cần set trainable = True cho base_model sau khi đóng băng các layer cụ thể\n    base_model.trainable = True \n    \n    # 4. Xây dựng lớp đầu ra (đã có L2 Regularization)\n    inputs = Input(shape=input_shape)\n    # training=True là cần thiết để đảm bảo các lớp Batch Normalization hoạt động đúng (cho phần không bị đóng băng)\n    x = base_model(inputs, training=True) \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    \n    outputs = Dense(num_classes, \n                    activation='linear',\n                    kernel_regularizer=l2(0.001)\n                   )(x) \n    return Model(inputs, outputs)\n\ndef load_data_from_df(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        X.append(np.load(row['filepath']))\n        y.append(row['label'])\n    return np.array(X), np.array(y)\n\ndef get_grad_cam(model, img_array, last_conv_layer_name, pred_index=None):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(tf.cast(img_array, tf.float32))\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef overlay_grad_cam(spec, heatmap, alpha=0.6):\n    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (spec.shape[0], spec.shape[1]))\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    jet = plt.cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap_resized.squeeze()]\n    spec_display = np.stack([spec]*3, axis=-1)\n    spec_display = (spec_display - spec_display.min()) / (spec_display.max() - spec_display.min())\n    superimposed_img = jet_heatmap * alpha + spec_display\n    superimposed_img = np.clip(superimposed_img, 0, 1)\n    return superimposed_img\n\nclass PDFReport(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, 'BAO CAO KET QUA HUAN LUYEN MO HINH AI', 0, 1, 'C')\n        self.ln(10)\n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Trang {self.page_no()}', 0, 0, 'C')\n    def chapter_title(self, title):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, title, 0, 1, 'L')\n        self.ln(5)\n    def chapter_body(self, content):\n        self.set_font('Arial', '', 10)\n        safe_content = content.encode('latin-1', 'replace').decode('latin-1')\n        self.multi_cell(0, 5, safe_content)\n        self.ln()\n    def add_image_section(self, title, img_path):\n        self.chapter_title(title)\n        if os.path.exists(img_path):\n            self.image(img_path, x=None, y=None, w=180)\n            self.ln(5)\n        else:\n            self.chapter_body(f\"Khong tim thay hinh anh: {img_path}\")\n\ndef authenticate_gdrive():\n    user_secrets = UserSecretsClient()\n    secret_value = user_secrets.get_secret(\"google_service_account_key\")\n    with open(\"service_account.json\", \"w\") as f:\n        f.write(secret_value)\n    scope = [\"https://www.googleapis.com/auth/drive\"]\n    gauth = GoogleAuth()\n    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\"service_account.json\", scope)\n    drive = GoogleDrive(gauth)\n    return drive\n\ndef upload_folder_to_drive(drive, folder_path, parent_folder_id):\n    folder_name = os.path.basename(folder_path)\n    print(f\"Đang tạo thư mục '{folder_name}' trên Google Drive...\")\n    folder_metadata = {'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder', 'parents': [{'id': parent_folder_id}]}\n    folder = drive.CreateFile(folder_metadata)\n    folder.Upload()\n    \n    print(f\"Bắt đầu tải nội dung của '{folder_name}'...\")\n    for item in tqdm(os.listdir(folder_path), desc=f\"Uploading {folder_name}\"):\n        item_path = os.path.join(folder_path, item)\n        if os.path.isfile(item_path):\n            gfile = drive.CreateFile({'title': item, 'parents': [{'id': folder['id']}]})\n            gfile.SetContentFile(item_path)\n            gfile.Upload(param={'supportsTeamDrives': True})\n        elif os.path.isdir(item_path):\n            upload_folder_to_drive(drive, item_path, folder['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T14:19:57.727544Z","iopub.execute_input":"2025-08-26T14:19:57.727816Z","iopub.status.idle":"2025-08-26T14:19:57.785000Z","shell.execute_reply.started":"2025-08-26T14:19:57.727792Z","shell.execute_reply":"2025-08-26T14:19:57.784225Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# CHUẨN BỊ DỮ LIỆU\nprint(\"Bắt đầu chuẩn bị và phân chia dữ liệu...\")\nall_files_to_split = []\nfor class_name in ALL_CLASSES:\n    source_dir = os.path.join(KAGGLE_PROCESSED_DATA_PATH, class_name)\n    if os.path.exists(source_dir):\n        files = glob.glob(os.path.join(source_dir, '*.npy'))\n        for f in files:\n            all_files_to_split.append({'filepath': f, 'label': class_name})\n\nall_data_df = pd.DataFrame(all_files_to_split)\nall_data_df['patient_id'] = all_data_df.apply(lambda row: get_patient_id(row['filepath'], row['label']), axis=1)\n\nprint(\"Tách tập Test cuối cùng (Hold-out set)...\")\npatient_ids = all_data_df['patient_id'].unique()\nnp.random.shuffle(patient_ids)\ntest_patient_count = int(len(patient_ids) * TEST_SPLIT_RATIO)\ntest_patients = patient_ids[:test_patient_count]\ntrain_val_patients = patient_ids[test_patient_count:]\n\ntest_df = all_data_df[all_data_df['patient_id'].isin(test_patients)].reset_index(drop=True)\ntrain_val_df = all_data_df[all_data_df['patient_id'].isin(train_val_patients)].reset_index(drop=True)\n\nprint(f\"Đã tách: {len(train_val_df)} mẫu cho Train/Validation (CV) và {len(test_df)} mẫu cho Test cuối cùng.\")\n\nle = LabelEncoder().fit(ALL_CLASSES)\nsample_spec = np.load(train_val_df['filepath'][0])\nINPUT_SHAPE = (sample_spec.shape[0], sample_spec.shape[1], 3)\nprint(f\"Kích thước input được cập nhật: {INPUT_SHAPE}\")\n\nprint(\"Đang fit StandardScaler...\")\nscaler_fit_sample_df = train_val_df.sample(n=min(len(train_val_df), 500), random_state=SEED)\nscaler_fit_data = []\nfor filepath in scaler_fit_sample_df['filepath']:\n    spec = np.load(filepath)\n    spec_3_channels = np.stack([spec]*3, axis=-1)\n    scaler_fit_data.append(spec_3_channels.flatten())\nscaler = StandardScaler().fit(scaler_fit_data)\nprint(\"Fit StandardScaler hoàn tất.\")\n\nskf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\ncv_data_to_split = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\nX_cv_paths = cv_data_to_split['filepath'].values\ny_cv_labels = le.transform(cv_data_to_split['label'])\ngroups_cv = cv_data_to_split['patient_id'].values\nfold_accuracies, fold_losses = [], []\n\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T14:19:57.785868Z","iopub.execute_input":"2025-08-26T14:19:57.786177Z","iopub.status.idle":"2025-08-26T14:20:03.789834Z","shell.execute_reply.started":"2025-08-26T14:19:57.786153Z","shell.execute_reply":"2025-08-26T14:20:03.789074Z"}},"outputs":[{"name":"stdout","text":"Bắt đầu chuẩn bị và phân chia dữ liệu...\nTách tập Test cuối cùng (Hold-out set)...\nĐã tách: 28054 mẫu cho Train/Validation (CV) và 5030 mẫu cho Test cuối cùng.\nKích thước input được cập nhật: (256, 126, 3)\nĐang fit StandardScaler...\nFit StandardScaler hoàn tất.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"tf.debugging.enable_check_numerics()\n# VÒNG LẶP Cross-Validation\n# try:\n#     strategy = tf.distribute.MirroredStrategy()\n#     print('Số lượng thiết bị: {}'.format(strategy.num_replicas_in_sync))\n# except RuntimeError as e:\n#     print(e)\n#     # Nếu chỉ có 1 GPU hoặc không có GPU, dùng chiến lược mặc định\n#     strategy = tf.distribute.get_strategy()\n\nactive_indices = [le.transform([c])[0] for c in CLASSES_TO_TRAIN]\n\nfor fold, (train_indices, val_indices) in enumerate(skf.split(X_cv_paths, y_cv_labels, groups_cv)):\n    fold_number = fold + 1\n    print(\"-\" * 50 + f\"\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\n\" + \"-\" * 50)\n    \n    train_paths, val_paths = X_cv_paths[train_indices], X_cv_paths[val_indices]\n    train_labels, val_labels = y_cv_labels[train_indices], y_cv_labels[val_indices]\n    \n    train_labels_onehot = tf.keras.utils.to_categorical(train_labels, num_classes=len(ALL_CLASSES))\n    val_labels_onehot = tf.keras.utils.to_categorical(val_labels, num_classes=len(ALL_CLASSES))\n    \n    # Tạo pipeline tf.data cho tập train\n    train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels_onehot))\n    train_ds = train_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n    train_ds = train_ds.batch(BATCH_SIZE)\n    if USE_DATA_AUGMENTATION:\n        train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n\n    # Tạo pipeline tf.data cho tập validation\n    val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels_onehot))\n    val_ds = val_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\n    val_ds = val_ds.cache()\n    val_ds = val_ds.batch(BATCH_SIZE)\n    val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n\n    #with strategy.scope():\n    # Gọi create_model (giả định bạn đã sửa nó để lớp Dense cuối có activation='linear')\n    model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipvalue=1.0)\n        \n    # --- THAY ĐỔI CHÍNH ĐỂ TĂNG CƯỜNG SỰ ỔN ĐỊNH ---\n    loss_function = None\n    if USE_FOCAL_LOSS:\n        # Sử dụng hàm focal loss mới làm việc với logits\n        loss_function = focal_loss_from_logits_optimized(active_indices=active_indices) \n    else:\n        # Sử dụng CategoricalCrossentropy với from_logits=True\n        loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n        \n    model.compile(optimizer=optimizer, \n                loss=loss_function, \n                metrics=['accuracy'], \n                jit_compile=False)\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                            factor=0.5, \n                            patience=5, \n                            min_lr=1e-8, \n                            verbose=1)\n\n    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, \n                        callbacks=[EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, min_delta=MIN_DELTA, restore_best_weights=True),\n                                    reduce_lr\n                                  ],\n                        verbose=1)\n    \n    # Code vẽ sơ đồ kết quả\n    plt.figure(figsize=(15, 6))\n    plt.suptitle(f'Training Metrics for Fold {fold_number}', fontsize=16)\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy vs. Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss vs. Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    \n    plot_filename = f'fold_{fold_number}_metrics.png'\n    plot_filepath = os.path.join(KAGGLE_OUTPUT_PATH, plot_filename)\n    plt.savefig(plot_filepath)\n    plt.close()\n    \n    print(f\"Đã lưu biểu đồ cho Fold {fold_number} tại: {plot_filepath}\")\n    \n    # Để evaluate mô hình có output là logits, không cần thay đổi gì ở đây\n    loss, accuracy = model.evaluate(val_ds, verbose=0)\n    print(f\"Fold {fold_number} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n    fold_losses.append(loss)\n    fold_accuracies.append(accuracy)\n\nprint(\"=\" * 50 + \"\\nKết quả Cross-Validation:\\n\" + f\"Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\" + f\"Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\" + \"=\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T14:20:03.790692Z","iopub.execute_input":"2025-08-26T14:20:03.790915Z"}},"outputs":[{"name":"stdout","text":"--------------------------------------------------\nBắt đầu Fold 1/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756218008.669381      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756218008.670089      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2025-08-26 14:20:14.565370: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_4}}\nI0000 00:00:1756218102.428830     106 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8224 - loss: 0.0830","output_type":"stream"},{"name":"stderr","text":"2025-08-26 14:30:44.824962: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_4}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 2s/step - accuracy: 0.8224 - loss: 0.0829 - val_accuracy: 0.4617 - val_loss: 0.4852 - learning_rate: 3.0000e-05\nEpoch 2/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 1s/step - accuracy: 0.7488 - loss: 0.1198 - val_accuracy: 0.4886 - val_loss: 0.4735 - learning_rate: 3.0000e-05\nEpoch 3/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 1s/step - accuracy: 0.7528 - loss: 0.1068 - val_accuracy: 0.5266 - val_loss: 0.3302 - learning_rate: 3.0000e-05\nEpoch 4/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 1s/step - accuracy: 0.7591 - loss: 0.0994 - val_accuracy: 0.5383 - val_loss: 0.2772 - learning_rate: 3.0000e-05\nEpoch 5/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 1s/step - accuracy: 0.7482 - loss: 0.0921 - val_accuracy: 0.5447 - val_loss: 0.2082 - learning_rate: 3.0000e-05\nEpoch 6/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.7569 - loss: 0.0948 - val_accuracy: 0.5410 - val_loss: 0.2592 - learning_rate: 3.0000e-05\nEpoch 7/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 1s/step - accuracy: 0.7556 - loss: 0.0964 - val_accuracy: 0.5565 - val_loss: 0.2789 - learning_rate: 3.0000e-05\nEpoch 8/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 1s/step - accuracy: 0.7685 - loss: 0.0807 - val_accuracy: 0.5517 - val_loss: 0.1996 - learning_rate: 3.0000e-05\nEpoch 9/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 1s/step - accuracy: 0.7774 - loss: 0.0799 - val_accuracy: 0.5553 - val_loss: 0.1894 - learning_rate: 3.0000e-05\nEpoch 10/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 1s/step - accuracy: 0.7498 - loss: 0.0924 - val_accuracy: 0.5549 - val_loss: 0.1976 - learning_rate: 3.0000e-05\nEpoch 11/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 1s/step - accuracy: 0.7536 - loss: 0.0811 - val_accuracy: 0.5590 - val_loss: 0.1814 - learning_rate: 3.0000e-05\nEpoch 12/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 1s/step - accuracy: 0.7687 - loss: 0.0741 - val_accuracy: 0.5612 - val_loss: 0.1794 - learning_rate: 3.0000e-05\nEpoch 13/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 1s/step - accuracy: 0.7788 - loss: 0.0692 - val_accuracy: 0.5606 - val_loss: 0.2035 - learning_rate: 3.0000e-05\nEpoch 14/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 1s/step - accuracy: 0.7358 - loss: 0.0884 - val_accuracy: 0.5599 - val_loss: 0.1893 - learning_rate: 3.0000e-05\nEpoch 15/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 1s/step - accuracy: 0.7528 - loss: 0.0805 - val_accuracy: 0.5599 - val_loss: 0.1820 - learning_rate: 3.0000e-05\nEpoch 16/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 1s/step - accuracy: 0.7502 - loss: 0.0885 - val_accuracy: 0.5613 - val_loss: 0.2148 - learning_rate: 3.0000e-05\nEpoch 17/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 1s/step - accuracy: 0.7747 - loss: 0.0741 - val_accuracy: 0.5592 - val_loss: 0.1793 - learning_rate: 3.0000e-05\nEpoch 18/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 1s/step - accuracy: 0.7530 - loss: 0.0842 - val_accuracy: 0.5633 - val_loss: 0.1818 - learning_rate: 3.0000e-05\nEpoch 19/50\n\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 1s/step - accuracy: 0.8097 - loss: 0.0660 - val_accuracy: 0.5621 - val_loss: 0.1853 - learning_rate: 3.0000e-05\nEpoch 20/50\n\u001b[1m 25/351\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:44\u001b[0m 1s/step - accuracy: 0.3721 - loss: 0.2159","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# HUẤN LUYỆN MÔ HÌNH CUỐI CÙNG\nprint(\"Bắt đầu huấn luyện lại mô hình cuối cùng trên toàn bộ dữ liệu Train+Validation...\")\nfinal_train_df = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\n\n# Tạo pipeline tf.data cho việc huấn luyện cuối cùng\nfinal_train_paths = final_train_df['filepath'].values\nfinal_train_labels = le.transform(final_train_df['label'])\nfinal_train_labels_onehot = tf.keras.utils.to_categorical(final_train_labels, num_classes=len(ALL_CLASSES))\n\nfinal_train_ds = tf.data.Dataset.from_tensor_slices((final_train_paths, final_train_labels_onehot))\nfinal_train_ds = final_train_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\nfinal_train_ds = final_train_ds.shuffle(buffer_size=len(final_train_paths))\nfinal_train_ds = final_train_ds.batch(BATCH_SIZE)\nif USE_DATA_AUGMENTATION:\n    final_train_ds = final_train_ds.map(augment, num_parallel_calls=AUTOTUNE)\nfinal_train_ds = final_train_ds.prefetch(buffer_size=AUTOTUNE)\n\n\nfinal_model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n\n# SỬA LỖI 1: Sử dụng clipvalue để đảm bảo ổn định\nfinal_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipvalue=1.0)\n\n# SỬA LỖI 2: Sử dụng đúng hàm loss 'from_logits'\nactive_indices = [le.transform([c])[0] for c in CLASSES_TO_TRAIN]\nloss_function = None\nif USE_FOCAL_LOSS:\n    loss_function = focal_loss_from_logits_optimized(active_indices=active_indices)\nelse:\n    loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n\nfinal_model.compile(optimizer=final_optimizer, \n                    loss=loss_function, \n                    metrics=['accuracy'], \n                    jit_compile=False) # Tắt jit_compile để tránh các lỗi tiềm ẩn\n\nrun_timestamp = datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d_%H-%M-%S\")\nmodel_checkpoint_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_final_model_{run_timestamp}.h5')\n\n# GỢI Ý 3: Chỉ dùng ModelCheckpoint và huấn luyện đủ số epochs để mô hình hội tụ tốt\nfinal_history = final_model.fit(final_train_ds, epochs=EPOCHS, \n                                callbacks=[ModelCheckpoint(filepath=model_checkpoint_path, \n                                                          save_best_only=True, \n                                                          monitor='loss',\n                                                          verbose=1)], \n                                verbose=1)\nprint(\"Huấn luyện mô hình cuối cùng hoàn tất.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ĐÁNH GIÁ MÔ HÌNH VÀ VẼ CÁC SƠ ĐỒ\nprint(\"\\nĐang đánh giá mô hình cuối cùng trên tập Test (Hold-out)...\")\nfinal_model.load_weights(model_checkpoint_path)\nfinal_test_df = test_df[test_df['label'].isin(CLASSES_TO_TRAIN)]\n\n\n\nX_test, y_test_labels = load_data_from_df(final_test_df)\ny_test_encoded = le.transform(y_test_labels)\ny_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=len(ALL_CLASSES))\nX_test = np.stack([X_test]*3, axis=-1)\nX_test_flat = X_test.reshape(X_test.shape[0], -1)\nX_test_scaled = scaler.transform(X_test_flat)\nX_test = np.nan_to_num(X_test_scaled).reshape(X_test.shape)\nprint(\"Tải dữ liệu test hoàn tất!\")\n\nloss, accuracy = final_model.evaluate(X_test, y_test_onehot, verbose=0)\nprint(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n\ny_pred_probs = final_model.predict(X_test)\ny_pred_encoded = np.argmax(y_pred_probs, axis=1)\n\ntrained_class_indices = np.unique(y_test_encoded)\ntarget_names_trained = le.inverse_transform(trained_class_indices)\n\nreport = classification_report(y_test_encoded, y_pred_encoded, target_names=target_names_trained, labels=trained_class_indices)\nprint(\"\\nClassification Report:\\n\", report)\n\nreport_figs_path = os.path.join(KAGGLE_OUTPUT_PATH, \"report_figures\")\nos.makedirs(report_figs_path, exist_ok=True)\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['accuracy'], label='Training Accuracy')\nplt.title('Biểu đồ Accuracy của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\naccuracy_plot_path = os.path.join(report_figs_path, f'final_accuracy_plot_{run_timestamp}.png')\nplt.savefig(accuracy_plot_path)\nplt.close()\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['loss'], label='Training Loss')\nplt.title('Biểu đồ Loss của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nloss_plot_path = os.path.join(report_figs_path, f'final_loss_plot_{run_timestamp}.png')\nplt.savefig(loss_plot_path)\nplt.close()\n\ncm = confusion_matrix(y_test_encoded, y_pred_encoded, labels=trained_class_indices)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_trained, yticklabels=target_names_trained)\nplt.title('Ma trận nhầm lẫn trên tập Test cuối cùng')\nplt.ylabel('Nhãn thật')\nplt.xlabel('Nhãn dự đoán')\ncm_plot_path = os.path.join(report_figs_path, f'confusion_matrix_{run_timestamp}.png')\nplt.savefig(cm_plot_path)\nplt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VẼ GRAD-CAM\nlast_conv_layer_name = None\nfor layer in reversed(final_model.layers):\n    if isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n        pooling_index = final_model.layers.index(layer)\n        last_conv_layer_name = final_model.layers[pooling_index - 1].name\n        break\nif last_conv_layer_name is None:\n    raise ValueError(\"Không thể tự động tìm thấy lớp phù hợp cho Grad-CAM.\")\nprint(f\"Đã tự động xác định lớp Grad-CAM: {last_conv_layer_name}\")\n\ngradcam_path = os.path.join(report_figs_path, \"grad_cam\")\nos.makedirs(gradcam_path, exist_ok=True)\nprint(\"Tạo hình ảnh Grad-CAM...\")\nresults_list = []\nfor i in range(len(y_test_encoded)):\n    true_label_encoded = y_test_encoded[i]\n    pred_label_encoded = y_pred_encoded[i]\n    confidence = y_pred_probs[i][pred_label_encoded]\n    is_correct = (true_label_encoded == pred_label_encoded)\n    results_list.append({'index': i, 'true_label': true_label_encoded, 'pred_label': pred_label_encoded, 'confidence': confidence, 'is_correct': is_correct})\nresults_df = pd.DataFrame(results_list)\n\nfor class_index, class_name in zip(trained_class_indices, target_names_trained):\n    correct_samples = results_df[(results_df['is_correct'] == True) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    incorrect_samples = results_df[(results_df['is_correct'] == False) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    for _, row in correct_samples.iterrows():\n        idx = int(row['index'])\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Đúng: {class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"correct_{class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n    for _, row in incorrect_samples.iterrows():\n        idx = int(row['index'])\n        pred_class_name = le.inverse_transform([int(row['pred_label'])])[0]\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Thật: {class_name}, Sai -> {pred_class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"incorrect_{class_name}_as_{pred_class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n\ncorrect_heatmaps = {label: [] for label in target_names_trained}\nincorrect_heatmaps = {label: [] for label in target_names_trained}\nfor i, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Calculating Avg Grad-CAMs\"):\n    idx = int(row['index'])\n    true_label_index = int(row['true_label'])\n    class_name = le.inverse_transform([true_label_index])[0]\n    img_array = X_test[idx][np.newaxis, ...]\n    heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=true_label_index)\n    if row['is_correct']:\n        if class_name in correct_heatmaps: correct_heatmaps[class_name].append(heatmap)\n    else:\n        if class_name in incorrect_heatmaps: incorrect_heatmaps[class_name].append(heatmap)\n\nfor class_name in target_names_trained:\n    if correct_heatmaps.get(class_name):\n        avg_heatmap_correct = np.mean(correct_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_correct)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Đúng cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\"))\n        plt.close()\n    if incorrect_heatmaps.get(class_name):\n        avg_heatmap_incorrect = np.mean(incorrect_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_incorrect)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Sai cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\"))\n        plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TẠO BÁO CÁO PDF\nprint(\"Tạo báo cáo PDF...\")\npdf = PDFReport()\npdf.add_page()\npdf.chapter_title(\"1. Tom tat cau hinh va Ket qua\")\nconfig_summary = f\"\"\"\n- Model ID: {MODEL_ID}\n- Thoi gian chay: {datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d %H:%M:%S\")}\n- Cac lop huan luyen: {', '.join(CLASSES_TO_TRAIN)}\n- K-Fold Cross-Validation: {N_SPLITS} folds\n\n--- KET QUA CROSS-VALIDATION ---\n- Validation Accuracy trung binh: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\n- Validation Loss trung binh: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\n\n--- KET QUA TREN TAP TEST CUOI CUNG ---\n- Test Loss: {loss:.4f}\n- Test Accuracy: {accuracy:.4f}\n\n--- CAU HINH CHI TIET ---\n- SEED: {SEED}\n- Epochs: {EPOCHS} (Patience: {EARLY_STOPPING_PATIENCE})\n- Batch Size: {BATCH_SIZE}\n- Learning Rate: {LEARNING_RATE}\n- Ham Loss: {'Focal Loss' if USE_FOCAL_LOSS else 'Categorical Crossentropy'}\n- Tang cuong du lieu: {'Co (SpecAugment)' if USE_DATA_AUGMENTATION else 'Khong'}\n- Kich thuoc Input: {INPUT_SHAPE}\n\"\"\"\npdf.chapter_body(config_summary)\npdf.add_image_section(\"2. Bieu do Huan luyen cua Mo hinh Cuoi cung\", accuracy_plot_path)\npdf.add_image_section(\"\", loss_plot_path)\npdf.chapter_title(\"3. Danh gia chi tiet tren tap Test\")\npdf.chapter_body(\"Bao cao phan loai chi tiet:\")\npdf.set_font('Courier', '', 8)\npdf.chapter_body(report)\npdf.add_image_section(\"Ma tran nham lan:\", cm_plot_path)\n\npdf.add_page()\npdf.chapter_title(\"4. Phan tich Grad-CAM\")\nfor class_name in target_names_trained:\n    pdf.chapter_body(f\"Lop: {class_name}\")\n    correct_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"correct_{class_name}_*_{run_timestamp}.png\")))\n    incorrect_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"incorrect_{class_name}_*_{run_timestamp}.png\")))\n    \n    x_pos, y_pos = pdf.get_x(), pdf.get_y()\n    for i, img_path in enumerate(correct_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if correct_imgs: y_pos += 45\n    for i, img_path in enumerate(incorrect_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if incorrect_imgs: y_pos += 45\n    pdf.set_y(y_pos)\n    \n    avg_correct_path = os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\")\n    avg_incorrect_path = os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\")\n    if os.path.exists(avg_correct_path):\n        pdf.image(avg_correct_path, w=80)\n    if os.path.exists(avg_incorrect_path):\n        pdf.image(avg_incorrect_path, w=80)\n    pdf.ln(10)\n\nreport_filename = f\"report_{MODEL_ID}_{run_timestamp}.pdf\"\nreport_filepath = os.path.join(KAGGLE_OUTPUT_PATH, report_filename)\npdf.output(report_filepath)\nprint(f\"Đã tạo báo cáo PDF tại: {report_filepath}\")\n\nprint(\"\\nBắt đầu quá trình tải kết quả lên Google Drive...\")\ndrive = authenticate_gdrive()\nupload_folder_to_drive(drive, KAGGLE_OUTPUT_PATH, DRIVE_RESULTS_FOLDER_ID)\nprint(\"Hoàn tất! Toàn bộ kết quả đã được lưu về Google Drive.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}