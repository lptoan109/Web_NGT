{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b80d5e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "papermill": {
     "duration": 10.165551,
     "end_time": "2025-10-16T11:14:29.210898",
     "exception": false,
     "start_time": "2025-10-16T11:14:19.045347",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang sử dụng TensorFlow phiên bản: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "print(f\"Đang sử dụng TensorFlow phiên bản: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0f9892",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 21.881854,
     "end_time": "2025-10-16T11:14:51.096894",
     "exception": false,
     "start_time": "2025-10-16T11:14:29.215040",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã định nghĩa xong 2 class custom: 'FinalModelCNN' và 'MacroF1Score'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ĐỊNH NGHĨA CÁC CLASS CUSTOM\n",
    "# =============================================================================\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(package=\"Custom\")\n",
    "class FinalModelCNN(tf.keras.Model):\n",
    "    def __init__(self, input_shape_config, num_classes_config, **kwargs):\n",
    "        super(FinalModelCNN, self).__init__(**kwargs)\n",
    "        self.input_shape_config = input_shape_config\n",
    "        self.num_classes_config = num_classes_config\n",
    "\n",
    "        # 1. Base Model (CNN)\n",
    "        self.base_model = tf.keras.applications.EfficientNetV2B2(\n",
    "        weights=None,  # <-- ĐÃ SỬA\n",
    "        include_top=False, \n",
    "        input_shape=self.input_shape_config\n",
    "    )\n",
    "        \n",
    "        # 2. Lớp Pooling để giảm chiều dữ liệu\n",
    "        self.gap = tf.keras.layers.GlobalAveragePooling2D(name=\"global_avg_pool\")\n",
    "        \n",
    "        # 3. Các lớp Dense (Head)\n",
    "        self.dense1 = tf.keras.layers.Dense(512, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(1e-5), name=\"dense_layer_1\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization(name=\"batch_norm_1\")\n",
    "        self.act1 = tf.keras.layers.Activation('relu', name=\"activation_1\")\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.3, name=\"dropout_layer_1\")\n",
    "        \n",
    "        self.dense2 = tf.keras.layers.Dense(256, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(1e-5), name=\"dense_layer_2\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization(name=\"batch_norm_2\")\n",
    "        self.act2 = tf.keras.layers.Activation('relu', name=\"activation_2\")\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.2, name=\"dropout_layer_2\")\n",
    "        \n",
    "        # 4. Lớp Output\n",
    "        self.dense_output = tf.keras.layers.Dense(self.num_classes_config, activation='linear', dtype='float32', name=\"output_layer\")\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.base_model(inputs, training=training)\n",
    "        x = self.gap(x, training=training) \n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x, training=training); x = self.act1(x); x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x, training=training); x = self.act2(x); x = self.dropout2(x, training=training)\n",
    "        outputs = self.dense_output(x)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(FinalModelCNN, self).get_config()\n",
    "        config.update({\n",
    "            'input_shape_config': self.input_shape_config,\n",
    "            'num_classes_config': self.num_classes_config,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(package=\"Custom\")\n",
    "class MacroF1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, name='f1_macro', **kwargs):\n",
    "        super(MacroF1Score, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.true_positives = self.add_weight(name='tp', shape=(num_classes,), initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', shape=(num_classes,), initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', shape=(num_classes,), initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_labels = tf.argmax(tf.nn.softmax(y_pred), axis=1)\n",
    "        y_true_labels = tf.argmax(y_true, axis=1)\n",
    "        cm = tf.math.confusion_matrix(y_true_labels, y_pred_labels, num_classes=self.num_classes, dtype=tf.float32)\n",
    "        tp = tf.linalg.diag_part(cm)\n",
    "        fp = tf.reduce_sum(cm, axis=0) - tp\n",
    "        fn = tf.reduce_sum(cm, axis=1) - tp\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "        macro_f1 = tf.reduce_mean(f1)\n",
    "        return macro_f1\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros(self.num_classes))\n",
    "        self.false_positives.assign(tf.zeros(self.num_classes))\n",
    "        self.false_negatives.assign(tf.zeros(self.num_classes))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MacroF1Score, self).get_config()\n",
    "        config.update({'num_classes': self.num_classes})\n",
    "        return config\n",
    "\n",
    "print(\"Đã định nghĩa xong 2 class custom: 'FinalModelCNN' và 'MacroF1Score'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cc0d2",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.014805,
     "end_time": "2025-10-16T11:14:51.115721",
     "exception": false,
     "start_time": "2025-10-16T11:14:51.100916",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thư mục làm việc hiện tại (BASE_DIR): e:\\NCKH\\dungcocach\\Web_NGT\\models\n",
      "Đang tìm model Keras tại: e:\\NCKH\\dungcocach\\Web_NGT\\models\\models\\CNN_from_NPY_no_val.keras\n",
      "Sẽ lưu TFLite tại: e:\\NCKH\\dungcocach\\Web_NGT\\models\\models_tflite\\CNN_from_NPY_no_val.tflite\n",
      "\n",
      "!!! LỖI KIỂM TRA: Không tìm thấy file tại đường dẫn trên. !!!\n"
     ]
    }
   ],
   "source": [
    "# --- CẤU HÌNH ---\n",
    "BASE_DIR = os.getcwd() \n",
    "SOURCE_MODEL_DIR = os.path.join(BASE_DIR, \"models\") \n",
    "DEST_TFLITE_DIR = os.path.join(BASE_DIR, \"models_tflite\") \n",
    "MODEL_TEST_NAME = \"CNN_from_NPY_no_val.keras\"\n",
    "# ------------------\n",
    "\n",
    "model_path = os.path.join(SOURCE_MODEL_DIR, MODEL_TEST_NAME)\n",
    "tflite_name = MODEL_TEST_NAME.replace(\".keras\", \".tflite\")\n",
    "dest_path = os.path.join(DEST_TFLITE_DIR, tflite_name)\n",
    "\n",
    "dest_path = os.path.normpath(dest_path) \n",
    "os.makedirs(os.path.normpath(DEST_TFLITE_DIR), exist_ok=True)\n",
    "\n",
    "print(f\"Thư mục làm việc hiện tại (BASE_DIR): {BASE_DIR}\")\n",
    "print(f\"Đang tìm model Keras tại: {model_path}\")\n",
    "print(f\"Sẽ lưu TFLite tại: {dest_path}\")\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"\\n!!! LỖI KIỂM TRA: Không tìm thấy file tại đường dẫn trên. !!!\")\n",
    "else:\n",
    "    print(\"\\nKiểm tra: Đã tìm thấy file model. Bắt đầu chuyển đổi...\")\n",
    "    try:\n",
    "        # =============================================================================\n",
    "        # === SỬA LỖI: Cung cấp custom_objects TRỰC TIẾP ===\n",
    "        # =============================================================================\n",
    "\n",
    "        # 1. Tải toàn bộ model\n",
    "        print(f\"\\n[1/3] Đang tải toàn bộ model (load_model) từ: {model_path}\")\n",
    "        \n",
    "        # === PHẦN SỬA LỖI ===\n",
    "        # (Đảm bảo bạn đã chạy Ô 2 để FinalModelCNN và MacroF1Score tồn tại)\n",
    "        # Chúng ta tạo một từ điển (dict) để ánh xạ TÊN (string) sang CLASS (object)\n",
    "        custom_objects = {\n",
    "            \"FinalModelCNN\": FinalModelCNN,\n",
    "            \"MacroF1Score\": MacroF1Score\n",
    "        }\n",
    "\n",
    "        # Truyền custom_objects VÀ compile=False vào hàm load_model\n",
    "        model = tf.keras.models.load_model(\n",
    "            model_path, \n",
    "            custom_objects=custom_objects,  # <--- SỬA LỖI Ở ĐÂY\n",
    "            compile=False                   # <--- Vẫn giữ compile=False\n",
    "        )\n",
    "        # ==================================\n",
    "        \n",
    "        print(\"[1/3] Tải model thành công.\")\n",
    "        \n",
    "        # 2. Khởi tạo bộ chuyển đổi\n",
    "        print(\"[2/3] Đang khởi tạo bộ chuyển đổi TFLite...\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        print(\"[2/3] Khởi tạo thành công.\")\n",
    "        \n",
    "        # 3. Chuyển đổi và Lưu\n",
    "        print(\"[3/3] Đang tiến hành lượng tử hóa và chuyển đổi...\")\n",
    "        tflite_model = converter.convert()\n",
    "        print(\"[3/3] Lượng tử hóa thành công.\")\n",
    "        \n",
    "        print(f\"    -> Đang lưu mô hình TFLite tại: {dest_path}\")\n",
    "        with open(dest_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        print(f\"\\n*** THÀNH CÔNG! Đã tạo file: {tflite_name} (Kích thước: {os.path.getsize(dest_path)} bytes) ***\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n!!! LỖI TOÀN BỘ KHI CHUYỂN ĐỔI: {e} !!!\")\n",
    "        print(\"--- Gợi ý: Hãy đảm bảo bạn đã CHẠY Ô 2 (định nghĩa class) trước khi chạy ô này. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0e7bd",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.035354,
     "end_time": "2025-10-16T11:14:51.154545",
     "exception": false,
     "start_time": "2025-10-16T11:14:51.119191",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- CẤU HÌNH ---\n",
    "# Lấy đường dẫn thư mục làm việc hiện tại (CWD)\n",
    "BASE_DIR = os.getcwd() \n",
    "SOURCE_MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "DEST_TFLITE_DIR = os.path.join(BASE_DIR, \"models_tflite\")\n",
    "MODEL_TEST_NAME = \"CNN_from_NPY_no_val.keras\"\n",
    "# ------------------\n",
    "\n",
    "model_path = os.path.join(SOURCE_MODEL_DIR, MODEL_TEST_NAME)\n",
    "tflite_name = MODEL_TEST_NAME.replace(\".keras\", \".tflite\")\n",
    "dest_path = os.path.join(DEST_TFLITE_DIR, tflite_name)\n",
    "\n",
    "os.makedirs(DEST_TFLITE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Thư mục làm việc hiện tại (BASE_DIR): {BASE_DIR}\")\n",
    "print(f\"Đang tìm model Keras tại: {model_path}\")\n",
    "print(f\"Sẽ lưu TFLite tại: {dest_path}\")\n",
    "\n",
    "# KIỂM TRA QUAN TRỌNG: File có tồn tại không?\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"\\n!!! LỖI KIỂM TRA: Không tìm thấy file tại đường dẫn trên. !!!\")\n",
    "    print(\"Vui lòng đảm bảo file .keras của bạn nằm trong thư mục 'models' ở gốc.\")\n",
    "else:\n",
    "    print(\"\\nKiểm tra: Đã tìm thấy file model. Bắt đầu chuyển đổi...\")\n",
    "    try:\n",
    "        # 1. Tải mô hình\n",
    "        print(\"\\n[1/4] Đang tải mô hình (load_model)...\")\n",
    "        # Chúng ta không cần 'custom_objects' vì các class đã được 'register' ở ô trên\n",
    "        model = tf.keras.models.load_model(\n",
    "            model_path, \n",
    "            compile=False  # Bỏ qua optimizer\n",
    "        )\n",
    "        print(\"[1/4] Tải mô hình thành công.\")\n",
    "\n",
    "        # 2. Khởi tạo bộ chuyển đổi\n",
    "        print(\"[2/4] Đang khởi tạo bộ chuyển đổi TFLite...\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        print(\"[2/4] Khởi tạo thành công.\")\n",
    "\n",
    "        # 3. Chuyển đổi\n",
    "        print(\"[3/4] Đang tiến hành lượng tử hóa (convert)... Vui lòng chờ...\")\n",
    "        tflite_model = converter.convert()\n",
    "        print(\"[3/4] Lượng tử hóa thành công.\")\n",
    "\n",
    "        # 4. Lưu file\n",
    "        print(f\"[4/4] Đang lưu mô hình TFLite tại: {dest_path}\")\n",
    "        with open(dest_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(\"[4/4] Lưu file thành công.\")\n",
    "        \n",
    "        print(f\"\\n*** THÀNH CÔNG! Đã tạo file: {tflite_name} (Kích thước: {os.path.getsize(dest_path)} bytes) ***\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n!!! LỖI TOÀN BỘ KHI CHUYỂN ĐỔI: {e} !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42fcedb",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 45.776843,
     "end_time": "2025-10-16T11:15:36.934878",
     "exception": false,
     "start_time": "2025-10-16T11:14:51.158035",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CHUẨN BỊ DỮ LIỆU TỪ CÁC FILE .NPY\n",
    "\n",
    "print(\"--- 3. Nạp Dữ liệu từ .npy ---\")\n",
    "try:\n",
    "    X_train_all = np.load(X_TRAIN_PATH)\n",
    "    y_train_all = np.load(Y_TRAIN_PATH)\n",
    "    \n",
    "    if os.path.exists(X_TEST_PATH) and os.path.exists(Y_TEST_PATH):\n",
    "        X_test = np.load(X_TEST_PATH)\n",
    "        y_test = np.load(Y_TEST_PATH)\n",
    "        print(\"Đã tải thành công tập Train, Val và Test.\")\n",
    "    else:\n",
    "        print(\"Cảnh báo: Không tìm thấy file X_test.npy hoặc y_test.npy.\")\n",
    "        X_test, y_test = None, None\n",
    "        \n",
    "    print(f\"Shape X_train_all: {X_train_all.shape}\")\n",
    "    print(f\"Shape y_train_all: {y_train_all.shape}\")\n",
    "\n",
    "    # Kiểm tra số lớp\n",
    "    unique_labels = np.unique(y_train_all)\n",
    "    if len(unique_labels) != NUM_CLASSES:\n",
    "        print(f\"Cảnh báo: Số lớp tìm thấy ({len(unique_labels)}) không khớp với NUM_CLASSES ({NUM_CLASSES}).\")\n",
    "        NUM_CLASSES = len(unique_labels)\n",
    "        print(f\"Đã cập nhật NUM_CLASSES thành {NUM_CLASSES}.\")\n",
    "    \n",
    "    # Đảm bảo target_names_str khớp\n",
    "    if len(target_names_str) != NUM_CLASSES:\n",
    "        raise ValueError(f\"Lỗi: 'target_names_str' có {len(target_names_str)} tên, nhưng NUM_CLASSES là {NUM_CLASSES}.\")\n",
    "\n",
    "    # Chuyển nhãn thành one-hot encoding\n",
    "    y_train_all_ohe = to_categorical(y_train_all, num_classes=NUM_CLASSES)\n",
    "    if y_test is not None:\n",
    "        y_test_ohe = to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "    # Nạp class weights nếu cần\n",
    "    class_weights_dict = None\n",
    "    if USE_CLASS_WEIGHTS:\n",
    "        if os.path.exists(CLASS_WEIGHTS_PATH):\n",
    "            class_weights_array = np.load(CLASS_WEIGHTS_PATH)\n",
    "            class_weights_dict = dict(enumerate(class_weights_array))\n",
    "            print(\"Đã tải và sẽ sử dụng class weights:\")\n",
    "            print(class_weights_dict)\n",
    "        else:\n",
    "            print(\"Cảnh báo: Đã bật USE_CLASS_WEIGHTS nhưng không tìm thấy file class_weights.npy.\")\n",
    "            USE_CLASS_WEIGHTS = False\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Lỗi nghiêm trọng: Không tìm thấy file dữ liệu .npy! Vui lòng kiểm tra đường dẫn DATA_DIR.\")\n",
    "    print(e)\n",
    "    # Dừng notebook ở đây nếu không có dữ liệu\n",
    "    raise SystemExit(\"Dừng do thiếu dữ liệu.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi không xác định khi tải dữ liệu: {e}\")\n",
    "    raise SystemExit(\"Dừng do lỗi tải dữ liệu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49800e",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 16254.012317,
     "end_time": "2025-10-16T15:46:30.968864",
     "exception": false,
     "start_time": "2025-10-16T11:15:36.956547",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# HUẤN LUYỆN CROSS-VALIDATION (TỪ DỮ LIỆU .NPY)\n",
    "\n",
    "print(\"\\n--- 5. Bắt đầu Huấn luyện Cross-Validation ---\")\n",
    "\n",
    "fold_accuracies, fold_losses, fold_aucs, fold_f1s = [], [], [], []\n",
    "# Sử dụng StratifiedKFold vì chúng ta đang làm việc với mảng NumPy\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_all, y_train_all)):\n",
    "    fold_number = fold + 1\n",
    "    print(\"-\" * 60 + f\"\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\n\" + \"-\" * 60)\n",
    "\n",
    "    # --- 5A: Chuẩn bị dữ liệu cho Fold ---\n",
    "    print(\"   - Chuẩn bị dữ liệu...\")\n",
    "    X_train_fold, X_val_fold = X_train_all[train_idx], X_train_all[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_all_ohe[train_idx], y_train_all_ohe[val_idx]\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train_fold, y_train_fold))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((X_val_fold, y_val_fold))\n",
    "\n",
    "    # Xóa các mảng NumPy lớn để tiết kiệm RAM\n",
    "    del X_train_fold, X_val_fold, y_train_fold, y_val_fold\n",
    "    gc.collect()\n",
    "\n",
    "    # Áp dụng tiền xử lý, shuffle, batch, prefetch\n",
    "    train_ds = train_ds.map(tf_preprocess_map, num_parallel_calls=AUTOTUNE)\n",
    "    if USE_DATA_AUGMENTATION:\n",
    "        train_ds = train_ds.map(augment_map, num_parallel_calls=AUTOTUNE) # Áp dụng Augmentation\n",
    "        \n",
    "    train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    val_ds = val_ds.map(tf_preprocess_map, num_parallel_calls=AUTOTUNE).batch(GLOBAL_BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    steps_per_epoch = len(train_idx) // GLOBAL_BATCH_SIZE\n",
    "    validation_steps = len(val_idx) // GLOBAL_BATCH_SIZE\n",
    "    print(f\"   - Steps per epoch: {steps_per_epoch}, Validation steps: {validation_steps}\")\n",
    "\n",
    "    # --- 5B: Huấn luyện 2 Giai đoạn ---\n",
    "    with strategy.scope():\n",
    "        # SỬA ĐỔI: Sử dụng FinalModelCNN\n",
    "        model = FinalModelCNN(\n",
    "            input_shape_config=INPUT_SHAPE, \n",
    "            num_classes_config=NUM_CLASSES\n",
    "        )\n",
    "        \n",
    "        if USE_FOCAL_LOSS:\n",
    "            loss_function = tf.keras.losses.CategoricalFocalCrossentropy(from_logits=True, gamma=GAMMA, label_smoothing=LABEL_SMOOTHING_VALUE)\n",
    "        else:\n",
    "            loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=LABEL_SMOOTHING_VALUE)\n",
    "            \n",
    "        # Giai đoạn 1: Huấn luyện Head (chỉ các lớp Dense)\n",
    "        print(\"\\n   --- Giai đoạn 1: Huấn luyện Head (Dense layers) ---\")\n",
    "        model.base_model.trainable = False\n",
    "        optimizer_head = tf.keras.optimizers.AdamW(learning_rate=STAGE1_HEAD_LR, weight_decay=WEIGHT_DECAY, epsilon=1e-7)\n",
    "        model.compile(optimizer=optimizer_head, loss=loss_function, metrics=['accuracy'], jit_compile=USE_XLA_COMPILATION)\n",
    "        history_1a = model.fit(train_ds, validation_data=val_ds, epochs=STAGE1_HEAD_EPOCHS, \n",
    "                               steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\n",
    "                               callbacks=[EarlyStopping(monitor='val_loss', patience=STAGE1_HEAD_PATIENCE, restore_best_weights=True)],\n",
    "                               class_weight=class_weights_dict if USE_CLASS_WEIGHTS else None,\n",
    "                               verbose=1)\n",
    "        \n",
    "        # Giai đoạn 2: Fine-tuning (toàn bộ model)\n",
    "        print(\"\\n   --- Giai đoạn 2: Fine-tuning ---\")\n",
    "        model.base_model.trainable = True\n",
    "        \n",
    "        if USE_COSINE_DECAY_RESTARTS:\n",
    "            first_decay_steps = RESTART_CYCLE_1_EPOCHS * steps_per_epoch\n",
    "            lr_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=STAGE1_FINETUNE_LR_INITIAL, first_decay_steps=first_decay_steps, t_mul=2.0, m_mul=0.9, alpha=0.1)\n",
    "            optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=WEIGHT_DECAY, epsilon=1e-7)\n",
    "            callbacks = [EarlyStopping(monitor='val_f1_macro', mode='max', patience=STAGE1_FINETUNE_PATIENCE, restore_best_weights=True, min_delta=MIN_DELTA, verbose=1), LearningRateLogger()]\n",
    "        else:\n",
    "            optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=STAGE1_FINETUNE_LR_INITIAL, weight_decay=WEIGHT_DECAY, epsilon=1e-7)\n",
    "            callbacks = [EarlyStopping(monitor='val_f1_macro', mode='max', patience=STAGE1_FINETUNE_PATIENCE, restore_best_weights=True, verbose=1)]\n",
    "        \n",
    "        f1_macro = MacroF1Score(num_classes=NUM_CLASSES)\n",
    "        model.compile(optimizer=optimizer_finetune, loss=loss_function, metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), f1_macro], jit_compile=USE_XLA_COMPILATION)\n",
    "        \n",
    "        history_1b = model.fit(train_ds, validation_data=val_ds, epochs=STAGE1_FINETUNE_TOTAL_EPOCHS, \n",
    "                               steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\n",
    "                               callbacks=callbacks,\n",
    "                               class_weight=class_weights_dict if USE_CLASS_WEIGHTS else None,\n",
    "                               verbose=1)\n",
    "    \n",
    "    # --- 5C: Lưu model, Vẽ biểu đồ, Đánh giá ---\n",
    "    model_save_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n",
    "    model.save(model_save_path)\n",
    "    print(f\"\\n   Đã lưu model cho Fold {fold_number} tại: {model_save_path}\")\n",
    "\n",
    "    print(\"\\n   --- Vẽ biểu đồ huấn luyện ---\")\n",
    "    plot_training_history(history_1a, \"Giai doan 1A - Head Training\", fold_number, KAGGLE_OUTPUT_PATH)\n",
    "    plot_training_history(history_1b, \"Giai doan 1B - Fine-tuning\", fold_number, KAGGLE_OUTPUT_PATH)\n",
    "\n",
    "    print(\"\\n   --- Đánh giá trên tập Validation ---\")\n",
    "    val_results = model.evaluate(val_ds, verbose=0, return_dict=True)\n",
    "    loss, accuracy, auc, f1 = val_results.get('loss', 0), val_results.get('accuracy', 0), val_results.get('auc', 0), val_results.get('f1_macro', 0)\n",
    "    print(f\"   Fold {fold_number} - Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc:.4f}, F1-Macro: {f1:.4f}\")\n",
    "    \n",
    "    fold_accuracies.append(accuracy); fold_losses.append(loss); fold_aucs.append(auc); fold_f1s.append(f1)\n",
    "    \n",
    "    print(\"\\n   \" + \"=\" * 50 + \"\\n   Kết quả Cross-Validation Tạm thời:\\n\" \n",
    "          + f\"     - Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\"\n",
    "          + f\"     - Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\"\n",
    "          + f\"     - AUC trung bình: {np.mean(fold_aucs):.4f} +/- {np.std(fold_aucs):.4f}\\n\"\n",
    "          + f\"     - F1-Macro trung bình: {np.mean(fold_f1s):.4f} +/- {np.std(fold_f1s):.4f}\\n\"\n",
    "          + \"   \" + \"=\" * 50)\n",
    "          \n",
    "    # --- 5D: Dọn dẹp bộ nhớ ---\n",
    "    print(\"\\n   --- Dọn dẹp bộ nhớ ---\")\n",
    "    try:\n",
    "        del model, train_ds, val_ds\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        print(\"   Đã dọn dẹp bộ nhớ thành công.\")\n",
    "    except NameError as e:\n",
    "        print(f\"   Một số biến có thể đã được dọn dẹp, bỏ qua lỗi: {e}\")\n",
    "\n",
    "# --- IN KẾT QUẢ TỔNG KẾT CUỐI CÙNG ---\\\n",
    "print(\"\\n\\n\" + \"=\" * 60 + \"\\nKẾT QUẢ CROSS-VALIDATION CUỐI CÙNG:\\n\" \n",
    "      + f\"  - Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\"\n",
    "      + f\"  - Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\"\n",
    "      + f\"  - Validation AUC trung bình: {np.mean(fold_aucs):.4f} +/- {np.std(fold_aucs):.4f}\\n\"\n",
    "      + f\"  - Validation F1-Macro trung bình: {np.mean(fold_f1s):.4f} +/- {np.std(fold_f1s):.4f}\\n\"\n",
    "      + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c4844",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ĐÁNH GIÁ CUỐI CÙNG TRÊN TẬP TEST (HOLD-OUT)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_test\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- 6. Bắt đầu Đánh giá cuối cùng trên tập Test (Hold-out) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Biến target_names_str đã được định nghĩa ở Cell 3\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# ĐÁNH GIÁ CUỐI CÙNG TRÊN TẬP TEST (HOLD-OUT)\n",
    "\n",
    "if X_test is not None and y_test is not None:\n",
    "    print(\"\\n--- 6. Bắt đầu Đánh giá cuối cùng trên tập Test (Hold-out) ---\")\n",
    "    \n",
    "    # Biến target_names_str đã được định nghĩa ở Cell 3\n",
    "    if len(target_names_str) != NUM_CLASSES:\n",
    "        raise ValueError(\"Lỗi: 'target_names_str' và 'NUM_CLASSES' không khớp.\")\n",
    "    \n",
    "    # --- 6A: Tạo Test Dataset ---\n",
    "    print(\"   - Chuẩn bị Test Dataset...\")\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test_ohe))\n",
    "    test_ds = test_ds.map(tf_preprocess_map, num_parallel_calls=AUTOTUNE) \\\n",
    "                       .batch(GLOBAL_BATCH_SIZE) \\\n",
    "                       .prefetch(AUTOTUNE)\n",
    "\n",
    "    # --- 6B: Lấy dự đoán từ 5 model ---\n",
    "    all_fold_preds = []\n",
    "    print(f\"   - Lấy dự đoán từ {N_SPLITS} models...\")\n",
    "    for fold_number in range(1, N_SPLITS + 1):\n",
    "        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"     - Đang tải model Fold {fold_number}...\")\n",
    "            with strategy.scope():\n",
    "                # SỬA LỖI: Đổi 'FinalModelCRNN' thành 'FinalModelCNN'\n",
    "                model = tf.keras.models.load_model(model_path, custom_objects={'FinalModelCNN': FinalModelCNN, 'MacroF1Score': MacroF1Score})\n",
    "            \n",
    "            print(f\"     - Đang dự đoán với model Fold {fold_number}...\")\n",
    "            fold_preds = model.predict(test_ds, verbose=1)\n",
    "            all_fold_preds.append(fold_preds)\n",
    "            \n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(f\"     - Cảnh báo: Không tìm thấy model Fold {fold_number} tại '{model_path}'.\")\n",
    "\n",
    "    # --- 6C: Tính trung bình dự đoán (Ensemble) ---\n",
    "    if all_fold_preds:\n",
    "        print(\"\\n   - Tính trung bình dự đoán...\")\n",
    "        avg_preds = np.mean(all_fold_preds, axis=0)\n",
    "        y_pred_probs_final = tf.nn.softmax(avg_preds).numpy() # Áp dụng softmax cho logits trung bình\n",
    "        y_pred_final = np.argmax(y_pred_probs_final, axis=1)\n",
    "        y_true_final = y_test # Sử dụng nhãn gốc (integer)\n",
    "        \n",
    "        # --- 6D: Tính toán và In các chỉ số cuối cùng ---\n",
    "        print(\"\\n   - Kết quả đánh giá cuối cùng trên tập Test:\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y_true_final, y_pred_final, target_names=target_names_str))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_true_final, y_pred_final)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_str, yticklabels=target_names_str)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix on Test Set')\n",
    "        cm_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_confusion_matrix.png')\n",
    "        plt.savefig(cm_path)\n",
    "        print(f\"   Đã lưu Confusion Matrix tại: {cm_path}\")\n",
    "        plt.show()\n",
    "\n",
    "        # Tính AUC đa lớp (One-vs-Rest)\n",
    "        y_test_ohe_for_auc = y_test_ohe\n",
    "        y_pred_probs_for_auc = y_pred_probs_final\n",
    "        \n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(NUM_CLASSES):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_ohe_for_auc[:, i], y_pred_probs_for_auc[:, i])\n",
    "            roc_auc[i] = sklearn_auc(fpr[i], tpr[i])\n",
    "\n",
    "        # (Phần tính Micro và Macro AUC giữ nguyên)\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_ohe_for_auc.ravel(), y_pred_probs_for_auc.ravel())\n",
    "        roc_auc[\"micro\"] = sklearn_auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(NUM_CLASSES)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(NUM_CLASSES):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_tpr /= NUM_CLASSES\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = sklearn_auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        # Vẽ ROC Curves\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Micro-average ROC (AUC = {roc_auc[\"micro\"]:.2f})', color='deeppink', linestyle=':', linewidth=4)\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Macro-average ROC (AUC = {roc_auc[\"macro\"]:.2f})', color='navy', linestyle=':', linewidth=4)\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green'])\n",
    "        for i, color in zip(range(NUM_CLASSES), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {target_names_str[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) on Test Set')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        roc_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_roc_curve.png')\n",
    "        plt.savefig(roc_path)\n",
    "        print(f\"   Đã lưu ROC Curve tại: {roc_path}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n   Không thể thực hiện đánh giá cuối cùng do thiếu kết quả từ các fold.\")\n",
    "else:\n",
    "     print(\"\\n--- Bỏ qua Đánh giá cuối cùng trên tập Test do thiếu dữ liệu Test (X_test hoặc y_test là None) ---\")\n",
    "\n",
    "print(\"\\n=== QUY TRÌNH HOÀN TẤT ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424666a9",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PHÂN TÍCH GRAD-CAM TRÊN TẬP TEST\n",
    "# Logic Grad-CAM này vẫn hoạt động cho CNN vì nó tìm 'top_conv' bên trong base_model\n",
    "\n",
    "print(\"--- Chuẩn bị dữ liệu Test cho việc phân tích Grad-CAM ---\\n\")\n",
    "if 'test_ds' in locals(): # Kiểm tra xem test_ds đã được tạo ở ô trước chưa\n",
    "    \n",
    "    @tf.function\n",
    "    def get_grad_cam_batched(model, img_batch):\n",
    "        \"\"\"\n",
    "        Phiên bản Grad-CAM linh hoạt, hoạt động với các model lồng nhau.\n",
    "        \"\"\"\n",
    "        # Tìm lớp Conv cuối cùng trong base_model\n",
    "        last_conv_layer = model.base_model.get_layer(\"top_conv\")\n",
    "        \n",
    "        # Tạo grad_model\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [model.inputs], [last_conv_layer.output, model.output]\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            last_conv_layer_output_value, preds = grad_model(img_batch)\n",
    "            pred_indices = tf.argmax(preds, axis=1)\n",
    "            class_channels = tf.gather(preds, pred_indices, axis=1, batch_dims=1)\n",
    "\n",
    "        grads = tape.gradient(class_channels, last_conv_layer_output_value)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n",
    "        \n",
    "        heatmap_batch = tf.einsum('bhwc,bc->bhw', last_conv_layer_output_value, pooled_grads)\n",
    "        heatmap_batch = tf.maximum(heatmap_batch, 0)\n",
    "        \n",
    "        max_vals = tf.reduce_max(heatmap_batch, axis=(1, 2), keepdims=True)\n",
    "        heatmap_batch = heatmap_batch / (max_vals + tf.keras.backend.epsilon())\n",
    "        \n",
    "        return heatmap_batch, preds\n",
    "\n",
    "    # Hàm run_grad_cam_analysis_final\n",
    "    def run_grad_cam_analysis_final(model, model_name, output_base_path, test_dataset):\n",
    "        print(f\"\\n--- Bắt đầu phân tích cho mô hình: {model_name} ---\")\n",
    "        \n",
    "        # SỬA LỖI: Sử dụng 'target_names_str' thay vì 'target_names'\n",
    "        results_by_class = { name: {'correct_heatmaps': [], 'correct_confidences': [], 'correct_images': [],\n",
    "                                    'incorrect_heatmaps': [], 'incorrect_confidences': [], 'incorrect_images': []}\n",
    "                            for name in target_names_str }\n",
    "\n",
    "        print(\"  - Xử lý các batch trên dataset...\")\n",
    "        for images_batch, labels_batch in tqdm(test_dataset, desc=f\"Analyzing {model_name}\"):\n",
    "            heatmap_batch, preds_batch = get_grad_cam_batched(model, images_batch)\n",
    "            y_pred_probs_batch = tf.nn.softmax(preds_batch).numpy()\n",
    "            y_pred_batch = np.argmax(y_pred_probs_batch, axis=1)\n",
    "            y_true_batch = np.argmax(labels_batch.numpy(), axis=1)\n",
    "\n",
    "            for i in range(images_batch.shape[0]):\n",
    "                y_pred, y_true = y_pred_batch[i], y_true_batch[i]\n",
    "                # SỬA LỖI: Sử dụng 'target_names_str'\n",
    "                true_class_name = target_names_str[y_true] \n",
    "                \n",
    "                if y_pred == y_true:\n",
    "                    results_by_class[true_class_name]['correct_heatmaps'].append(heatmap_batch[i].numpy())\n",
    "                    results_by_class[true_class_name]['correct_confidences'].append(y_pred_probs_batch[i, y_pred])\n",
    "                    results_by_class[true_class_name]['correct_images'].append(images_batch[i].numpy())\n",
    "                else:\n",
    "                    results_by_class[true_class_name]['incorrect_heatmaps'].append(heatmap_batch[i].numpy())\n",
    "                    results_by_class[true_class_name]['incorrect_confidences'].append(y_pred_probs_batch[i, y_pred])\n",
    "                    results_by_class[true_class_name]['incorrect_images'].append(images_batch[i].numpy())\n",
    "        \n",
    "        # (Bạn có thể thêm code ở đây để lưu các heatmap đã thu thập được)\n",
    "        print(f\"  - Phân tích cho {model_name} hoàn tất.\")\n",
    "\n",
    "    \n",
    "    # --- VÒNG LẶP CHÍNH ĐỂ PHÂN TÍCH 5 FOLDS ---\n",
    "    grad_cam_main_path = os.path.join(KAGGLE_OUTPUT_PATH, \"grad_cam_detailed_analysis\")\n",
    "    os.makedirs(grad_cam_main_path, exist_ok=True)\n",
    "    \n",
    "    for fold_number in range(1, N_SPLITS + 1):\n",
    "        print(f\"\\n---> Bắt đầu phân tích Grad-CAM cho Fold {fold_number}/{N_SPLITS}...\")\n",
    "        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Bỏ qua Fold {fold_number}, không tìm thấy file.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with strategy.scope():\n",
    "                # SỬA LỖI: Đổi 'FinalModel' thành 'FinalModelCNN'\n",
    "                model = tf.keras.models.load_model(model_path, custom_objects={'FinalModelCNN': FinalModelCNN, 'MacroF1Score': MacroF1Score})\n",
    "            \n",
    "            model_name = f\"fold_{fold_number}\"\n",
    "            fold_output_path = os.path.join(grad_cam_main_path, model_name)\n",
    "            os.makedirs(fold_output_path, exist_ok=True)\n",
    "            \n",
    "            # Gọi hàm phân tích với test_ds (đã được batch)\n",
    "            run_grad_cam_analysis_final(model, model_name, fold_output_path, test_ds)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"!!! Lỗi khi phân tích Grad-CAM cho Fold {fold_number}: {e}\")\n",
    "            \n",
    "    print(\"\\n--- Toàn bộ quá trình phân tích Grad-CAM đã hoàn tất ---\")\n",
    "else:\n",
    "    print(\"Lỗi: Không tìm thấy 'test_ds'. Vui lòng chạy ô đánh giá (Cell 7) trước.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe40d01",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CHUYỂN ĐỔI SANG TFLITE\n",
    "\n",
    "print(\"--- Bắt đầu quy trình chuyển đổi 5-Fold sang TFLite ---\")\n",
    "if 'fold_f1s' in locals() and len(fold_f1s) == N_SPLITS:\n",
    "    \n",
    "    # Dùng X_train_all để tạo representative dataset\n",
    "    \n",
    "    for fold_number in range(1, N_SPLITS + 1):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"--- Bắt đầu chuyển đổi cho Fold {fold_number} ---\")\n",
    "        \n",
    "        MODEL_PATH = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n",
    "        TFLITE_MODEL_PATH = os.path.join(KAGGLE_OUTPUT_PATH, f'model_fold_{fold_number}_quantized.tflite')\n",
    "\n",
    "        if not os.path.exists(MODEL_PATH):\n",
    "            print(f\"Lỗi: Không tìm thấy file model tại '{MODEL_PATH}'. Bỏ qua fold này.\")\n",
    "            continue\n",
    "\n",
    "        print(\"Đang tải lại model .keras...\")\n",
    "        with strategy.scope():\n",
    "            # SỬA LỖI: Đổi 'FinalModel' thành 'FinalModelCNN'\n",
    "            model_to_convert = tf.keras.models.load_model(MODEL_PATH, custom_objects={'FinalModelCNN': FinalModelCNN, 'MacroF1Score': MacroF1Score})\n",
    "\n",
    "        print(f\"Đang tạo representative dataset...\")\n",
    "        def representative_data_gen():\n",
    "            # Lấy 150 mẫu ngẫu nhiên từ TẬP TRAIN GỐC để hiệu chỉnh\n",
    "            for i in np.random.choice(len(X_train_all), 150, replace=False):\n",
    "                img = X_train_all[i]\n",
    "                # Sử dụng hàm tiền xử lý đã được cập nhật\n",
    "                img_processed = preprocess_npy_image(img) \n",
    "                yield [tf.expand_dims(img_processed, axis=0)]\n",
    "\n",
    "        print(f\"Đang chuyển đổi mô hình của Fold {fold_number}...\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model_to_convert)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_data_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.float32\n",
    "        converter.inference_output_type = tf.float32\n",
    "\n",
    "        tflite_quant_model = converter.convert()\n",
    "\n",
    "        with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "            f.write(tflite_quant_model)\n",
    "        \n",
    "        print(f\"Đã lưu thành công model TFLite cho Fold {fold_number} tại: {TFLITE_MODEL_PATH}\")\n",
    "        print(f\"Kích thước file: {len(tflite_quant_model) / (1024 * 1024):.2f} MB\")\n",
    "        \n",
    "        del model_to_convert\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nHoàn tất chuyển đổi cho cả 5 mô hình!\")\n",
    "else:\n",
    "    print(\"Lỗi: Không tìm thấy kết quả của 5 fold. Vui lòng chạy ô huấn luyện (Cell 6) trước.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8575381,
     "sourceId": 13506368,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16337.907779,
   "end_time": "2025-10-16T15:46:33.160586",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-16T11:14:15.252807",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
